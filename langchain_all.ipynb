{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Searching or questioning all the sources\n",
    "In this notebook, we create a chain that can ask all the different sources a question. Using functions we can choose the right source. We use the language model to make the selection.\n",
    "- Product search: use the VectorStore retriever making use of Amazon OpenSearch Service\n",
    "- Question: use the VectorStore QA retriever to use content from the vector store and OpenAI to write an asnwer\n",
    "- Find Opening times: Use a normal query against Amazon OpenSearch Service"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cbd160780d4f13e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialise the OpenSearch connection \n",
    "Notice that we do not provide a default alias. We need to provide the name of the index or alias on each request."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fe5671ee80d4fb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-04T13:44:32.813157Z",
     "start_time": "2023-09-04T13:44:31.295873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a connection to the Amazon OpenSearch Cluster\n"
     ]
    }
   ],
   "source": [
    "from retriever import find_auth_opensearch, OpenSearchClient\n",
    "\n",
    "config = find_auth_opensearch()\n",
    "client = OpenSearchClient(config)\n",
    "\n",
    "if client.ping():\n",
    "    print(\"We have a connection to the Amazon OpenSearch Cluster\")\n",
    "else:\n",
    "    print(\"ERROR: no connection to the Amazon OpenSearch Cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialise the product search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d76075311321c998"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from opensearchpy import RequestsHttpConnection\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "vector_store_products = OpenSearchVectorSearch(\n",
    "    index_name=\"sg-products\",\n",
    "    embedding_function=OpenAIEmbeddings(openai_api_key=os.getenv('OPEN_AI_API_KEY')),\n",
    "    opensearch_url=f\"https://{config['host']}:{config['port']}\",\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    http_auth=config[\"auth\"],\n",
    "    connection_class=RequestsHttpConnection\n",
    ")\n",
    "\n",
    "def execute_product_search(query: str):\n",
    "    found_docs = vector_store_products.similarity_search_with_score(query=query, text_field=\"title\", vector_field=\"title_vector\")\n",
    "    results = []\n",
    "    for doc, _score in found_docs:\n",
    "        results.append({\"title\": doc.page_content, \"score\": _score})\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T14:11:24.660608Z",
     "start_time": "2023-09-04T14:11:24.644741Z"
    }
   },
   "id": "e8e95161efdcfc53"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Frodo™ & Gollem™', 'score': 0.7835052}, {'title': 'Aragorn™ & Arwen™', 'score': 0.7829712}, {'title': 'Gandalf de Grijze™ & Balrog™', 'score': 0.75238377}, {'title': 'Slag om Endor™ helden', 'score': 0.7370234}]\n"
     ]
    }
   ],
   "source": [
    "print(execute_product_search(query=\"The lord of the rings\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T13:52:13.285089Z",
     "start_time": "2023-09-04T13:52:11.509215Z"
    }
   },
   "id": "c5d95e0190684883"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialise the content search"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddb348a691367e41"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "vector_store = OpenSearchVectorSearch(\n",
    "    index_name=\"sg-content\",\n",
    "    embedding_function=OpenAIEmbeddings(openai_api_key=os.getenv('OPEN_AI_API_KEY')),\n",
    "    opensearch_url=f\"https://{config['host']}:{config['port']}\",\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    http_auth=config[\"auth\"],\n",
    "    connection_class=RequestsHttpConnection\n",
    ")\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain import PromptTemplate, OpenAI\n",
    "\n",
    "prompt_template = \"\"\"Use the context to answer the question. If you don't know the \n",
    "    answer, just say that you don't know, don't make up an answer.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Question: {question}:\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": custom_prompt}\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(openai_api_key=os.getenv('OPEN_AI_API_KEY')),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")\n",
    "\n",
    "def execute_content_search(query: str):\n",
    "    return chain.run(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T14:11:32.638165Z",
     "start_time": "2023-09-04T14:11:32.622941Z"
    }
   },
   "id": "8ca315ee528588c0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Our return policy can be found on the Returns & Refunds page. You can access this page from the bottom of the home page.\n"
     ]
    }
   ],
   "source": [
    "print(execute_content_search(\"What is your return policy\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T13:57:11.034981Z",
     "start_time": "2023-09-04T13:57:09.180624Z"
    }
   },
   "id": "8cd0e139cb6e3e89"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions import create_openai_fn_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def run_conversation(message_content: str):\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=os.getenv('OPEN_AI_API_KEY'))\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a service with access to multiple data sources. Each data source is represented by a different function.\"),\n",
    "            (\"human\", \"Make calls to the relevant function to answer the provided question or search for a product. Always provided the exact query as provided by the user to the function: {input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    functions = [execute_content_search, execute_product_search]\n",
    "    function_chain = create_openai_fn_chain(\n",
    "        functions=functions,\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=True)\n",
    "\n",
    "    return function_chain.run(message_content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T14:16:51.104014Z",
     "start_time": "2023-09-04T14:16:51.086363Z"
    }
   },
   "id": "ae92568005949a28"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "\n",
    "\n",
    "def run_agent(message_content: str):\n",
    "    llm = ChatOpenAI(model=\"gpt-4\", temperature=0, openai_api_key=os.getenv('OPEN_AI_API_KEY'))\n",
    "\n",
    "    tools = [\n",
    "        Tool(name=\"ExecuteContentSearch\",\n",
    "             func=execute_content_search,\n",
    "             description=\"Useful for obtaining answers to questions about help for the website, your account and sustainability.\"\n",
    "             ),\n",
    "        Tool(name=\"ExecuteProductSearch\",\n",
    "             func=execute_product_search,\n",
    "             description=\"Useful for finding products related to the search terms that are provided.\"\n",
    "             ),\n",
    "    ]\n",
    "\n",
    "    agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.OPENAI_FUNCTIONS, verbose=True)\n",
    "    return agent.run(message_content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T14:16:54.133610Z",
     "start_time": "2023-09-04T14:16:54.120957Z"
    }
   },
   "id": "9d6ae061098402ab"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `ExecuteContentSearch` with `reusable packaging`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m What is [Your Company Name]'s commitment to reusable packaging?\n",
      "\n",
      "[Your Company Name] is committed to reducing single-use plastics and opting for biodegradable, compostable, or recyclable packaging materials. We prioritize items that align with our commitment to a greener future, focusing on eco-friendly materials and products designed for longevity and reusability.\u001B[0m\u001B[32;1m\u001B[1;3mOur company is committed to reducing single-use plastics and opting for biodegradable, compostable, or recyclable packaging materials. We prioritize items that align with our commitment to a greener future, focusing on eco-friendly materials and products designed for longevity and reusability.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Our company is committed to reducing single-use plastics and opting for biodegradable, compostable, or recyclable packaging materials. We prioritize items that align with our commitment to a greener future, focusing on eco-friendly materials and products designed for longevity and reusability.\n"
     ]
    }
   ],
   "source": [
    "# message = \"lord of the rings\"\n",
    "message = \"Do you use reusable packaging\"\n",
    "\n",
    "response = run_agent(message_content=message)\n",
    "\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-04T14:17:51.428079Z",
     "start_time": "2023-09-04T14:17:40.493530Z"
    }
   },
   "id": "533d045ffe0fea82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
